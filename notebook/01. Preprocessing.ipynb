{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    TODO : Run data preparation without filling in NAs at all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pickle\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prep 1: melt and append"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load full data\n",
    "trn = pd.read_csv('../input/train_ver2.csv')\n",
    "tst = pd.read_csv('../input/test_ver2.csv')\n",
    "labels = pd.read_csv('../input/labels.csv').astype(int)\n",
    "\n",
    "# prepare lag data\n",
    "trn_dates = ['2015-01-28','2015-02-28','2015-03-28','2015-04-28','2015-05-28']\n",
    "tst_dates = ['2016-01-28','2016-02-28','2016-03-28','2016-04-28','2016-05-28']\n",
    "\n",
    "temp = trn[trn['fecha_dato'] == '2015-06-28']['ncodpers']\n",
    "trn_ncodpers = temp[(labels[trn['fecha_dato'] == '2015-06-28'].sum(axis=1) > 0).values].values.tolist()\n",
    "tst_ncodpers = np.unique(tst['ncodpers']).tolist()\n",
    "\n",
    "trn_trim = trn[trn['fecha_dato'].isin(trn_dates)]\n",
    "trn_trim = trn_trim[trn_trim['ncodpers'].isin(trn_ncodpers)]\n",
    "tst_trim = trn[trn['fecha_dato'].isin(tst_dates)]\n",
    "tst_trim = tst_trim[tst_trim['ncodpers'].isin(tst_ncodpers)]\n",
    "\n",
    "# melt labels for trn\n",
    "\n",
    "fecha_dato = trn['fecha_dato']\n",
    "train_index = (labels[fecha_dato == '2015-06-28'].sum(axis=1) > 0)\n",
    "train_index = train_index[train_index == True]\n",
    "train = trn.ix[train_index.index]\n",
    "train.iloc[:,24:] = labels.ix[train_index.index]\n",
    "\n",
    "trn_june = []\n",
    "for ind, (run, row) in enumerate(train.iterrows()):\n",
    "    for i in range(24):\n",
    "        if row[24+i] == 1:\n",
    "            temp = row[:24].values.tolist()\n",
    "            temp.append(i)\n",
    "            trn_june.append(temp)\n",
    "            \n",
    "# define and save target separately\n",
    "target = pd.DataFrame(trn_june)[24].values.tolist()\n",
    "print('# target shape : ({})'.format(len(target)))\n",
    "\n",
    "# make full data set \n",
    "trn_june = pd.DataFrame(trn_june, columns=trn.columns[:25]).iloc[:,:-1]\n",
    "trn = pd.concat([trn_trim, trn_june], axis=0)\n",
    "tst = pd.concat([tst_trim, tst], axis=0)\n",
    "print(trn.shape, tst.shape)\n",
    "\n",
    "# save data\n",
    "trn.to_csv('../input/trn_append.csv', index=False)\n",
    "tst.to_csv('../input/tst_append.csv', index=False)\n",
    "target.to_csv('../input/target.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/IPython/core/interactiveshell.py:2717: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/IPython/core/interactiveshell.py:2717: DtypeWarning: Columns (4,37,42,47) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "trn = pd.read_csv('../input/trn_append.csv')\n",
    "tst = pd.read_csv('../input/tst_append.csv')\n",
    "target = pd.DataFrame(pickle.load(open('../input/target.pkl','rb')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prep 2: Label Encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# clean data\n",
    "skip_cols = ['fecha_dato','ncodpers']\n",
    "target_cols = ['ind_ahor_fin_ult1', 'ind_aval_fin_ult1', 'ind_cco_fin_ult1',\n",
    "               'ind_cder_fin_ult1', 'ind_cno_fin_ult1', 'ind_ctju_fin_ult1',\n",
    "               'ind_ctma_fin_ult1', 'ind_ctop_fin_ult1', 'ind_ctpp_fin_ult1',\n",
    "               'ind_deco_fin_ult1', 'ind_deme_fin_ult1', 'ind_dela_fin_ult1',\n",
    "               'ind_ecue_fin_ult1', 'ind_fond_fin_ult1', 'ind_hip_fin_ult1',\n",
    "               'ind_plan_fin_ult1', 'ind_pres_fin_ult1', 'ind_reca_fin_ult1',\n",
    "               'ind_tjcr_fin_ult1', 'ind_valo_fin_ult1', 'ind_viv_fin_ult1',\n",
    "               'ind_nomina_ult1', 'ind_nom_pens_ult1', 'ind_recibo_ult1']\n",
    "\n",
    "for col in trn.columns:\n",
    "    if col in skip_cols:\n",
    "        continue\n",
    "    \n",
    "    if col == 'ind_empleado':\n",
    "        trn[col].fillna('S', inplace=True)\n",
    "    elif col == 'age':\n",
    "        trn[col].replace(' NA',0,inplace=True)\n",
    "        trn[col] = trn[col].astype(str).astype(int)\n",
    "        trn[col] = trn[col].astype(str).astype(int)\n",
    "        continue\n",
    "    elif col == 'fecha_alta':\n",
    "        trn[col] = ((pd.to_datetime(trn['fecha_dato']) - pd.to_datetime(trn[col].fillna('2015-07-01')))/ np.timedelta64(1, 'D')).astype(int)\n",
    "        tst[col] = ((pd.to_datetime(tst['fecha_dato']) - pd.to_datetime(tst[col]))/np.timedelta64(1, 'D')).astype(int)\n",
    "        continue\n",
    "    elif col == 'antiguedad':\n",
    "        trn[col].replace('     NA',-1,inplace=True)\n",
    "        trn[col] = trn[col].astype(str).astype(int)\n",
    "        tst[col] = tst[col].astype(str).astype(int)\n",
    "        continue\n",
    "    elif col == 'ult_fec_cli_1t':\n",
    "        trn[col] = ((pd.to_datetime(trn['fecha_dato']) - pd.to_datetime(trn[col].fillna('2015-06-30')))/ np.timedelta64(1, 'D')).astype(int)\n",
    "        tst[col] = ((pd.to_datetime(tst['fecha_dato']) - pd.to_datetime(tst[col].fillna('2016-01-03')))/np.timedelta64(1, 'D')).astype(int)\n",
    "        continue\n",
    "    elif col == 'indrel_1mes':\n",
    "        tst[col].replace('1','1.0',inplace=True)\n",
    "        tst[col].replace('2','1.0',inplace=True)\n",
    "        tst[col].replace('2.0','1.0',inplace=True)\n",
    "        tst[col].replace(2.0,'1.0',inplace=True)\n",
    "        tst[col].replace('3','3.0',inplace=True)\n",
    "        tst[col].replace('4','3.0',inplace=True)\n",
    "        tst[col].replace(4.0,'3.0',inplace=True)\n",
    "        tst[col].replace('4.0','3.0',inplace=True)\n",
    "        tst[col].replace('P','3.0',inplace=True)\n",
    "    elif col == 'tiprel_1mes':\n",
    "        tst[col].replace('N','I',inplace=True)\n",
    "        tst[col].replace('R','P',inplace=True)\n",
    "    elif col == 'indresi':\n",
    "        trn[col].fillna('N',inplace=True)\n",
    "    elif col == 'indext':\n",
    "        trn[col].fillna('S',inplace=True)\n",
    "    elif col == 'indfall':\n",
    "        trn[col].fillna('N',inplace=True)\n",
    "    elif col == 'tipodom':\n",
    "        trn.drop([col], axis=1, inplace=True)\n",
    "        tst.drop([col], axis=1, inplace=True)\n",
    "        continue\n",
    "    elif col == 'ind_actividad_cliente':\n",
    "        trn[col].fillna(0.0, inplace=True)\n",
    "    elif col == 'renta':\n",
    "        tst[col].replace('         NA',0,inplace=True)\n",
    "        trn[col].fillna(-1, inplace=True)\n",
    "        tst[col].fillna(-1, inplace=True)\n",
    "        trn[col] = trn[col].astype(str).astype(float).astype(int)\n",
    "        tst[col] = tst[col].astype(str).astype(float).astype(int)\n",
    "        continue\n",
    "    elif col in target_cols:\n",
    "        trn[col].fillna(0, inplace=True)\n",
    "        trn[col] = trn[col].astype(int)\n",
    "        tst[col].fillna(0, inplace=True)\n",
    "        tst[col] = tst[col].astype(int)\n",
    "        \n",
    "    lb = LabelEncoder()\n",
    "    lb.fit(pd.concat([trn[col].astype(str), tst[col].astype(str)], axis=0))\n",
    "    trn[col] = lb.transform(trn[col].astype(str))\n",
    "    tst[col] = lb.transform(tst[col].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# display column names\n",
    "trn.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# clean utility\n",
    "col = 'ind_actividad_cliente'\n",
    "print('='*50)\n",
    "print(np.unique(trn[col].astype(str)), np.unique(tst[col].astype(str)))\n",
    "print('='*50)\n",
    "#lb = LabelEncoder()\n",
    "#lb.fit(pd.concat([trn[col].astype(str), tst[col].astype(str)], axis=0))\n",
    "#print(np.unique(lb.transform(trn[col].astype(str))), np.unique(lb.transform(tst[col].astype(str))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# check clean\n",
    "for col in trn.columns:\n",
    "    print('-'*50)\n",
    "    print(trn[col].dtype, col)\n",
    "    print(trn[col].dtype, col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trn.to_csv('../input/trn_append_lb.csv', index=False)\n",
    "tst.to_csv('../input/tst_append_lb.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## prep 3: append lag\n",
    "    - for each ncodpers in June data, append Jan~May (48x5) to single June data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trn_june = trn[trn['fecha_dato'] == '2015-06-28'].drop(target_cols, axis=1)\n",
    "trn_othr = trn[trn['fecha_dato'] != '2015-06-28']\n",
    "tst_june = tst[tst['fecha_dato'] == '2016-06-28'].drop(target_cols, axis=1)\n",
    "tst_othr = tst[tst['fecha_dato'] != '2016-06-28']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "st = time.time()\n",
    "drop_cols = ['fecha_dato','ncodpers']\n",
    "\n",
    "print('# Appending trn data.. {} rows'.format(trn_june.shape[0]))\n",
    "trn_append = []\n",
    "for i, ncodper in enumerate(trn_june['ncodpers']):\n",
    "    temp = trn_othr[trn_othr['ncodpers'] == ncodper].drop(drop_cols, axis=1)\n",
    "    if temp.shape[0] == 0:\n",
    "        row = ['NA']*225\n",
    "    else:\n",
    "        row = np.hstack([temp.shift(periods=i).iloc[-1,:] for i in range(temp.shape[0])]).tolist()\n",
    "    trn_append.append(trn_june.iloc[i].drop(drop_cols).values.tolist() + row)\n",
    "    \n",
    "    if i % int(trn_june.shape[0]/10) == 0:\n",
    "        print('# {} rows.. {} secs..'.format(i, round(time.time() - st),2))\n",
    "\n",
    "st = time.time()\n",
    "print('# Appending tst data.. {} rows'.format(tst_june.shape[0]))\n",
    "tst_append = []\n",
    "for i, ncodper in enumerate(tst_june['ncodpers']):\n",
    "    temp = tst_othr[tst_othr['ncodpers'] == ncodper].drop(drop_cols, axis=1)\n",
    "    if temp.shape[0] == 0:\n",
    "        row = ['NA']*225\n",
    "    else:\n",
    "        row = np.hstack([temp.shift(periods=i).iloc[-1,:] for i in range(temp.shape[0])]).tolist()\n",
    "    tst_append.append(tst_june.iloc[i].drop(drop_cols).values.tolist() + row)\n",
    "    \n",
    "    if i % int(tst_june.shape[0]/10) == 0:\n",
    "        print('# {} rows.. {} secs..'.format(i, round(time.time() - st),2))\n",
    "\n",
    "# 150 secs for trn\n",
    "# 9964 secs for tst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(len(trn_append),len(tst_append))\n",
    "print(len(trn_append[0]), len(tst_append[0]))\n",
    "\n",
    "# 45619, 929615\n",
    "# 246, 246"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "colnames = trn_june.drop(drop_cols, axis=1).columns.values.tolist()\n",
    "suffixes = ['_lag_one','_lag_two','_lag_thr','_lag_fou','_lag_fiv']\n",
    "for suffix in suffixes:\n",
    "    for col in trn_othr.drop(drop_cols, axis=1).columns.values.tolist():\n",
    "        colnames.append(col+suffix)\n",
    "print(len(colnames))\n",
    "# 246"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# initialize column names\n",
    "trn = pd.DataFrame(trn_append, columns=colnames)\n",
    "tst = pd.DataFrame(tst_append, columns=colnames)\n",
    "print('# trn : {} | tst : {}'.format(trn.shape, tst.shape))\n",
    "# trn : (45619, 246) | tst : (929615, 246)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# do not fillin na for now\n",
    "#trn_trim.fillna(0,inplace=True)\n",
    "#tst_trim.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trn.to_csv('../input/train_append_lb_lag.csv', index=False)\n",
    "tst.to_csv('../input/test_append_lb_lag.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "    - Remove non-important features\n",
    "    - add sum of targets\n",
    "    - number of occurances via NA count [just do naCount]\n",
    "    - avg of non-target columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_cols =  ['ind_ahor_fin_ult1', 'ind_aval_fin_ult1', 'ind_cco_fin_ult1',\\\n",
    "                'ind_cder_fin_ult1', 'ind_cno_fin_ult1',  'ind_ctju_fin_ult1',\\\n",
    "                'ind_ctma_fin_ult1', 'ind_ctop_fin_ult1', 'ind_ctpp_fin_ult1',\\\n",
    "                'ind_deco_fin_ult1', 'ind_deme_fin_ult1', 'ind_dela_fin_ult1',\\\n",
    "                'ind_ecue_fin_ult1', 'ind_fond_fin_ult1', 'ind_hip_fin_ult1',\\\n",
    "                'ind_plan_fin_ult1', 'ind_pres_fin_ult1', 'ind_reca_fin_ult1',\\\n",
    "                'ind_tjcr_fin_ult1', 'ind_valo_fin_ult1', 'ind_viv_fin_ult1',\\\n",
    "                'ind_nomina_ult1',   'ind_nom_pens_ult1', 'ind_recibo_ult1']\n",
    "lags = ['_lag_one','_lag_two','_lag_thr','_lag_fou','_lag_fiv']\n",
    "diffs = [['fiv','fou'],['fou','thr'],['thr','two'],['two','one']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trn = pd.read_csv('../input/train_append_lb_lag.csv')\n",
    "tst = pd.read_csv('../input/test_append_lb_lag.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fe v1\n",
    "trn['na_count'] = trn.isnull().sum(axis=1)/45\n",
    "tst['na_count'] = tst.isnull().sum(axis=1)/45\n",
    "\n",
    "for lag in lags:\n",
    "    target_sum = 0\n",
    "    trn['target_sum' + lag] = (trn[[col + lag for col in target_cols]].sum(axis=1))\n",
    "    tst['target_sum' + lag] = (tst[[col + lag for col in target_cols]].sum(axis=1))\n",
    "    \n",
    "cols = ['ind_actividad_cliente', 'ult_fec_cli_1t']\n",
    "for col in cols:\n",
    "    trn[col + lag + '_avg'] = (trn[[col + lag for lag in lags]]).mean(axis=1)\n",
    "    tst[col + lag + '_avg'] = (tst[[col + lag for lag in lags]]).mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fe v2\n",
    "for col in target_cols:\n",
    "    trn[col + '_sum'] = (trn[[col + lag for lag in lags]].sum(axis=1))\n",
    "    tst[col + '_sum'] = (tst[[col + lag for lag in lags]].sum(axis=1))\n",
    "    \n",
    "for diff in diffs:\n",
    "    pre = diff[0]\n",
    "    post = diff[1]\n",
    "    trn['target_diff_'+post+'-'+pre] = trn['target_sum_lag_'+post] - trn['target_sum_lag_'+pre]\n",
    "    tst['target_diff_'+post+'-'+pre] = tst['target_sum_lag_'+post] - tst['target_sum_lag_'+pre]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trn.to_csv('../input/train_append_lb_lag_fe_v2.csv', index=False)\n",
    "tst.to_csv('../input/test_append_lb_lag_fe_v2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trn = pd.read_csv('../input/train_append_lb_lag_fe_v2.csv')\n",
    "tst = pd.read_csv('../input/test_append_lb_lag_fe_v2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for col in target_cols:\n",
    "    for diff in diffs:\n",
    "        pre = diff[0]\n",
    "        post = diff[1]\n",
    "        trn[col + '_label_lag_' + post] = trn[col + '_lag_' + post] - trn[col + '_lag_' + pre]\n",
    "        tst[col + '_label_lag_' + post] = tst[col + '_lag_' + post] - tst[col + '_lag_' + pre]\n",
    "        \n",
    "\n",
    "trn['unique_target_count'] = (trn[[col + '_sum' for col in target_cols]] > 0).astype(int).sum(axis=1)\n",
    "tst['unique_target_count'] = (tst[[col + '_sum' for col in target_cols]] > 0).astype(int).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trn.to_csv('../input/train_append_lb_lag_fe_v3.csv', index=False)\n",
    "tst.to_csv('../input/test_append_lb_lag_fe_v3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ncodpers\n",
    "\n",
    "temp_trn = pd.read_csv('../input/trn_append_lb.csv', usecols=['ncodpers','fecha_dato'])\n",
    "temp_tst = pd.read_csv('../input/tst_append_lb.csv', usecols=['ncodpers','fecha_dato'])\n",
    "\n",
    "trn_ncodpers = temp_trn[temp_trn['fecha_dato'] == '2015-06-28']['ncodpers']\n",
    "tst_ncodpers = temp_tst[temp_tst['fecha_dato'] == '2016-06-28']['ncodpers']\n",
    "\n",
    "trn_ncodpers.reset_index(drop=True).to_csv('../input/trn_ncodpers.csv', index=False)\n",
    "tst_ncodpers.reset_index(drop=True).to_csv('../input/tst_ncodpers.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# correlation plot\n",
    "\n",
    "corr_mat = trn.corr(method='pearson')\n",
    "\n",
    "# Generate a mask for the upper triangle\n",
    "mask = np.zeros_like(corr_mat, dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(200, 150))\n",
    "\n",
    "# Generate a custom diverging colormap\n",
    "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "sns.heatmap(corr_mat, mask=mask, cmap=cmap, vmax=.3,\n",
    "            square=True, xticklabels=5, yticklabels=5,\n",
    "            linewidths=.5, cbar_kws={\"shrink\": .5}, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
